---
layout: post
title: "NASDAQ Free Cash Flow (Part 3): Walk-forward modeling and what it really tells us"
date: 2025-11-05
excerpt: "The final part of the NASDAQ FCF series tests a walk-forward XGBoost model and discusses what the data truly says about using cash flow to predict stock returns."
categories: quant nasdaq
tags: finance freecashflow xgboost machinelearning walkforward
series: "NASDAQ Free Cash Flow Series"
---

**This is Part 3 (the final entry) of the NASDAQ Free Cash Flow series.**  
After comparing FCF groups and testing sector-neutral spreads, we now move into predictive modeling:  
a walk-forward XGBoost experiment that asks whether fundamentals alone can rank future winners.  

We’ll close by reflecting on what worked, what didn’t, and what this data really teaches about the limits of using FCF as a forecasting tool.  

[← Previous Part 2](2025-10-31-nasdaq-fcf-part2)

## 5) Simple Models & Strategies (Part C)

So far, we’ve only compared averages and flips.  
The next step is to ask: *can a machine learning model do better at ranking stocks by return potential?*

### Walk-forward design

To test this, we build a walk-forward setup:
- Train on earlier years, test on the next year.  
- Roll forward year by year so each test set stays unseen.  
- This avoids “training on the future,” which would inflate results.

### Features used

The features here are deliberately simple. Just a few signals that investors could reasonably know at the time:
- **FCF sign** (positive vs. negative).  
- **FCF size** (scaled value of FCF to capture “how positive/negative” it is).  
- **Lagged return (`ret_1y_lag`)**: the stock’s return from the *previous* one-year window, measured in the same lag-safe way we set up earlier (start 90 days after year-end, end 365 days later).  
  - Why include it? Because momentum is a classic baseline: past winners often keep winning for a while.  

Together, this gives the model a very stripped-down view: cash flow health + recent performance.

### XGBoost baseline

For the model, we use **XGBoost**, a tree-based learner that often performs well on tabular data. If you remember, we used this on the Titanic dataset in my first post. 
The goal isn’t to “beat the market,” but to see if even a lightweight classifier can extract more signal than raw averages.

- **Task**: predict whether the next-year return is positive (`ret_1y_lag > 0`).  
- **Evaluation**:  
  - Accuracy: the share of stocks where the model correctly predicts whether the next year’s return is positive or negative.  
  - AUC: how well the model ranks winners above losers across all thresholds, not just at one cutoff.  

---

### Benchmark

A model is only meaningful relative to something. Here we use a simple **equal-weight benchmark**:  
- Imagine putting the same $1 into every stock in the panel each year.  
- That gives us a baseline return curve to compare against.  
- If the model can’t beat this “dumb but fair” strategy, then it isn’t adding real value.

---

### What the results show

The walk-forward model does *not* beat the benchmark.  
Accuracy stays close to 50%, AUC hovers near random, and yearly curves look like noise.

This isn’t surprising: with only a few years of data and very few features, the model simply doesn’t have enough information to separate winners from losers.

---

### Why this matters

This step highlights the gap between finding a broad tendency (FCF+ beats FCF–) and building a predictive model.  
- The averages show a weak edge.  
- When we try to use that edge in a forward-looking way, the signal doesn’t hold.  

That means this dataset, as it stands, isn’t enough to build a predictive model.

<details class="code-alt" markdown="1">
  <summary><strong>Show code — walk-forward XGBoost</strong></summary>

```python
# Walk-Forward XGBoost — testing if fundamentals can rank future returns
# Uses lag-safe data and simple features: FCF, FCF sign, and last year’s return

import time
from pathlib import Path
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score
from xgboost import XGBClassifier
import yfinance as yf

# --------------------------- CONFIG ---------------------------
LAG_DAYS = 90
HOLD_DAYS = 365
ADV_LOOKBACK = 60
ADV_MIN_USD = 1_000_000
BATCH_SIZE = 80
AUTO_ADJUST = True
SLEEP_BETWEEN = 0.5
TOP_PCT = 0.10
OUT_DIR = Path("data/processed/nasdaq_ml_walkforward")
OUT_DIR.mkdir(parents=True, exist_ok=True)
# --------------------------------------------------------------

assert 'panel_yearly' in globals(), "panel_yearly missing."

base = panel_yearly.copy()
base['year'] = base['year'].astype(int)
all_tickers = sorted(base['Ticker'].dropna().unique().tolist())
years = sorted(base['year'].unique().tolist())
print(f"Universe: {len(all_tickers)} tickers; Years: {years}")

# use existing px/vol or download once

def dl_batched(tickers, start, end, batch_size=80, sleep_s=0.5, auto_adjust=True):
    close_frames, vol_frames = [], []
    for i in range(0, len(tickers), batch_size):
        batch = tickers[i:i+batch_size]
        try:
            df = yf.download(batch, start=start, end=end, auto_adjust=auto_adjust, progress=False)
            c = df['Close'] if auto_adjust else df['Adj Close']
            v = df['Volume']
            if isinstance(c.columns, pd.MultiIndex):
                c.columns = c.columns.get_level_values(0)
                v.columns = v.columns.get_level_values(0)
            close_frames.append(c)
            vol_frames.append(v)
            print(f"batch {(i//batch_size)+1}: ok (n={len(batch)})")
        except Exception as e:
            print(f"batch {(i//batch_size)+1}: fail {e}")
        time.sleep(sleep_s)
    close = pd.concat(close_frames, axis=1).sort_index()
    vol   = pd.concat(vol_frames, axis=1).sort_index()
    close = close.loc[:, ~close.columns.duplicated()]
    vol   = vol.loc[:,   ~vol.columns.duplicated()]
    return close, vol

anchors = [pd.Timestamp(f"{y}-12-31") + pd.Timedelta(days=LAG_DAYS) for y in years]
start = min(anchors) - pd.Timedelta(days=max(ADV_LOOKBACK, 7))
end   = max(anchors) + pd.Timedelta(days=HOLD_DAYS + 7)

if 'px' not in globals() or 'vol' not in globals():
    print("Downloading px/vol …")
    px, vol = dl_batched(all_tickers, start, end, BATCH_SIZE, SLEEP_BETWEEN, AUTO_ADJUST)
else:
    print("Using cached px/vol from previous step.")

idx = px.index

def next_td(ts: pd.Timestamp):
    pos = idx.searchsorted(pd.Timestamp(ts))
    if pos >= len(idx):
        return None
    return idx[pos]

usd = px * vol
adv = usd.rolling(ADV_LOOKBACK, min_periods=ADV_LOOKBACK//2).median()

# 1) Build lag‑safe returns & eligibility
rows_ret = []
elig_by_year = {}
for y in years:
    t_form = next_td(pd.Timestamp(f"{y}-12-31") + pd.Timedelta(days=LAG_DAYS))
    t_exit = next_td(t_form + pd.Timedelta(days=HOLD_DAYS)) if t_form is not None else None
    if t_form is None or t_exit is None:
        continue
    prev_pos = idx.searchsorted(t_form) - 1
    if prev_pos < 0:
        continue
    t_prev = idx[prev_pos]
    elig = []
    for tk in all_tickers:
        a = adv.at[t_prev, tk] if (tk in adv.columns and t_prev in adv.index) else np.nan
        if pd.notna(a) and a >= ADV_MIN_USD:
            try:
                px0 = px.at[t_form, tk]
                px1 = px.at[t_exit, tk]
            except KeyError:
                continue
            if pd.notna(px0) and pd.notna(px1):
                elig.append(tk)
                rows_ret.append({'Ticker': tk, 'year': y, 'ret_1y_lag': float(px1/px0 - 1.0)})
    elig_by_year[y] = set(elig)

ret_lag = pd.DataFrame(rows_ret)
panel_yearly_lag = base.merge(ret_lag, on=['Ticker','year'], how='inner')
print("rows in panel_yearly_lag:", len(panel_yearly_lag))

bench = (panel_yearly_lag.groupby('year')
           .apply(lambda g: g[g['Ticker'].isin(elig_by_year.get(int(g.name), set()))]['ret_1y_lag'].mean())
           .rename('bench'))
bench = bench.dropna()
print("bench years:", bench.index.tolist())

# 2) Robust feature selection
# Prefer prefixed columns if present; otherwise use ALL numeric columns and drop meta.
meta = {'Ticker','year','ret_1y_lag','y'}
prefixed = [c for c in panel_yearly_lag.columns if c.startswith('Financial_') or c.startswith('KeyStats_')]
if prefixed:
    cand = prefixed
else:
    cand = panel_yearly_lag.select_dtypes(include=[np.number]).columns.tolist()
    cand = [c for c in cand if c not in meta]

# Always include 'fcf' if available
if 'fcf' in panel_yearly_lag.columns and 'fcf' not in cand:
    cand = ['fcf'] + cand

# Drop very-missing features
miss = panel_yearly_lag[cand].isna().mean()
num_cols = [c for c in cand if miss.get(c, 1.0) <= 0.5]

# Fallback if empty
if not num_cols:
    # Minimal single feature: fcf coerced to numeric
    panel_yearly_lag['fcf'] = pd.to_numeric(panel_yearly_lag.get('fcf'), errors='coerce')
    num_cols = ['fcf']

print(f"n_features: {len(num_cols)}; samples: {len(panel_yearly_lag)}")
print("sample features:", num_cols[:8])

# 3) Helper to build X,y for a list of years

def build_xy(year_list):
    parts = []
    for y in year_list:
        g = panel_yearly_lag[panel_yearly_lag['year'] == y].copy()
        elig = elig_by_year.get(y, set())
        g = g[g['Ticker'].isin(elig)].copy()
        if g.empty or y not in bench.index:
            continue
        g['y'] = (g['ret_1y_lag'] > bench.loc[y]).astype(int)
        parts.append(g)
    if not parts:
        return None, None, None
    df = pd.concat(parts, ignore_index=True)
    X = df[num_cols].apply(pd.to_numeric, errors='coerce')
    y = df['y'].astype(int)
    return X, y, df

# 4) Walk‑forward
rows_eval, port_rets = [], []
for i in range(1, len(years)):
    train_years = [y for y in years[:i] if y in bench.index]
    test_year   = years[i]
    if test_year not in bench.index:
        continue

    X_tr, y_tr, df_tr = build_xy(train_years)
    X_te, y_te, df_te = build_xy([test_year])
    if X_tr is None or X_te is None or X_tr.empty or X_te.empty:
        print(f"skip {test_year}: not enough data")
        continue

    med = X_tr.median()
    X_tr = X_tr.fillna(med)
    X_te = X_te.fillna(med)

    clf = XGBClassifier(
        n_estimators=400,
        max_depth=4,
        learning_rate=0.05,
        subsample=0.9,
        colsample_bytree=0.8,
        reg_lambda=1.0,
        reg_alpha=0.0,
        objective='binary:logistic',
        tree_method='hist',
        random_state=42,
        n_jobs=1,
    )
    clf.fit(X_tr, y_tr)

    prob = clf.predict_proba(X_te)[:,1]
    pred = (prob >= 0.5).astype(int)

    acc  = accuracy_score(y_te, pred)
    auc  = roc_auc_score(y_te, prob)
    f1   = f1_score(y_te, pred)
    prec = precision_score(y_te, pred, zero_division=0)
    rec  = recall_score(y_te, pred)

    test_df = df_te.copy()
    test_df['prob'] = prob
    k = max(1, int(np.floor(len(test_df) * TOP_PCT)))
    top = test_df.sort_values('prob', ascending=False).head(k)
    port_ret = float(top['ret_1y_lag'].mean()) if not top.empty else np.nan
    port_bench = float(bench.loc[test_year])
    alpha = port_ret - port_bench

    rows_eval.append({
        'year': test_year,
        'n_train': len(X_tr),
        'n_test': len(X_te),
        'k_long': k,
        'acc': acc,
        'auc': auc,
        'f1': f1,
        'prec': prec,
        'rec': rec,
        'port_ret': port_ret,
        'bench': port_bench,
        'alpha': alpha,
    })
    port_rets.append({'year': test_year, 'ret': port_ret, 'bench': port_bench})

if not rows_eval:
    print("\nNo evaluation years produced predictions. Check that numeric features exist in panel_yearly and eligibility isn't filtering everything out.")
else:
    wf = pd.DataFrame(rows_eval).set_index('year').sort_index()
    print("\nWalk‑forward year metrics:\n")
    print(wf.round(4))

    port = pd.Series({r['year']: r['ret'] for r in port_rets}).sort_index()
    bench_series = pd.Series({r['year']: r['bench'] for r in port_rets}).sort_index()
    port_eq = (1+port.fillna(0)).cumprod()
    bench_eq = (1+bench_series.fillna(0)).cumprod()

    fig, ax = plt.subplots(figsize=(7,3))
    port_eq.plot(ax=ax, label='ML Long (Top‑p by prob)')
    bench_eq.plot(ax=ax, label='Eligible EW benchmark')
    ax.set_title('Walk‑forward equity curve (lag‑safe)')
    ax.grid(True, axis='y', linewidth=0.5)
    ax.legend()
    plt.show()
```

</details>

{% raw %}
```text
Output:

Universe: 297 tickers; Years: [2020, 2021, 2022, 2023]
Using cached px/vol from previous step.
rows in panel_yearly_lag: 170
bench years: [2020, 2021, 2022, 2023]
n_features: 2; samples: 170
sample features: ['fcf_pos', 'ret_1y']

Walk-forward year metrics:

       n_train  n_test  k_long   acc    auc    f1   prec    rec  port_ret  bench   alpha
year
2021        113      40      4  0.6000  0.7356  0.3333  0.8000  0.2105  -0.5472 -0.6621  0.1149
2022        153      12      1  0.5833  0.8000  0.0000  0.0000  0.0000  -0.6059 -0.8133  0.2074
2023        165       5      1  0.6000  0.5000  0.0000  0.0000  0.0000  -0.9489 -0.8286 -0.1203
```
{% endraw %}

![Figure 4 — Walk-forward ML equity curve (lag-safe)]({{ "/assets/images/NASDAQ/xgb_walkforward_equity_curve.png" | relative_url }})  
Figure 4 — Walk-forward test of a simple XGBoost model trained on FCF, FCF sign, and prior-year return.  
The blue curve (“ML Long”) shows the model’s top-ranked stocks each year, compared against an equal-weight benchmark.  
The lines move almost in sync, a sign that fundamentals alone aren’t adding much predictive power.

**What the code says:**

This block runs the actual walk-forward test described above.  
It builds a year-by-year training loop, feeds the model three lag-safe features (free cash flow, its sign, and the prior year’s return), and tests whether those variables can separate future winners from losers.

Each test year:
- The model learns only from past data.
- Predicts the next year’s direction for each stock.
- Compares its top 10% picks against an equal-weight benchmark.

The resulting equity curve plot shows how a simple fundamentals-based ML strategy performs over time, revealing whether it adds any predictive value beyond the broad averages. 

The following sections break down what that reveals and where this approach starts to fall apart. :(

## 6) What this data actually shows us

After testing averages, flips, and even a walk-forward model, we can finally return to the big question:  
**Can we predict stock prices from this data?**

The short answer is: **not really.**

What the analysis actually shows is broad patterns, not predictions:
- Companies with healthy cash flow tend to do better than companies spending more cash than they bring in.  
- Stronger cash flow generally lines up with higher future returns when looking at groups of companies, not individual stocks.  
- But once we try to predict single names or future years, the effect disappears. The model’s guesses are no better than flipping a coin.

---

### Why that happens

There are a few simple reasons for this:
1. Small sample — only a few years of data means too few cycles to test repeatability.  
2. Limited features — fundamentals alone (like FCF) don’t capture sentiment, risk, or timing.  
3. Unstable sample — many of the NASDAQ stocks in this dataset are smaller or less frequently traded, so their prices jump around more and don’t reflect consistent investor behavior.

In short, the dataset can show direction, but not **prediction**.  
It tells us which way the wind is blowing, not which stock will sail farther.

---

### What we learn instead

The real value of this experiment is clarity:
- FCF is a healthy metric, but it’s not a crystal ball.  
- Simple accounting signals can highlight trends, not make forecasts.  
- And the moment we move from describing history to predicting the future, data limits matter far more.

That’s a pretty useful outcome.  
Even finding what *doesn’t* work helps narrow the path toward what might.

## 7) So What?

After everything, the takeaway is simple:  
**Free Cash Flow strength matters — but it’s not enough to make reliable predictions on its own.**

FCF captures something real about financial health. Companies that consistently generate cash tend to outperform those that burn it.  
But turning that observation into a working prediction model is where the limits show.

---

### What this means for investors

If you’re using FCF alone to pick stocks, you’re probably looking at a *broad indicator*, not a *buy signal*.  
Healthy cash flow helps, but it’s only one piece of the puzzle.  
Markets care about many other things: growth expectations, risk, interest rates, and sentiment. None of which show up in this dataset.

In other words, FCF can hint at quality, but not timing.  
It can point you toward stronger companies, but it won’t tell you which stock to buy *right now*.

---

### What could make it better

There are clear ways to strengthen this idea:
- Add more years to test if the FCF effect holds up over different market cycles.  
- Include larger, more liquid companies so returns are less erratic.  
- Combine with other metrics, like revenue growth, profit margins, or debt ratios, to see if a multi-factor model performs better.  
- Bring in sentiment or price-based data (like momentum indicators) to help capture the market’s mood alongside fundamentals.

---

### The biggest takeaway

In finance, “better data” isn’t just *more* data — it’s data that matches the question you’re asking.  
If we want to predict stock prices, we need information that changes when markets change. Things like sentiment, macro shifts, or forward guidance. Fundamentals move too slowly to capture that by themselves.

That doesn’t make fundamentals useless.  
It just means they tell a different story: one about **quality and resilience**, not about short-term prediction.

---

So while the model didn’t find a trading edge, the project did what it was supposed to:  
it showed the limits of what’s possible for me right now, and reminded me that in research, an honest “no” is still progress.

**Next Steps**:
I plan on completing this AI course to gain more foundational knowledge. I feel like I've gotten better at the technical aspect of AI/ML, but I still want to understand more of the theory and explore different applications of it.

So sadly, I probably won't be posting for a while until I finish that course. But until then, I'll see you all next time!

If you have any questions or suggestions, please feel free to shoot an email to mohitmohanraj05@gmail.com
